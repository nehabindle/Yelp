{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yelp_Neha_TensorFlow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nehabindle/Yelp-Review-Classification/blob/master/Yelp_Neha_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pifiySPxxOyO",
        "colab_type": "code",
        "outputId": "0b13b9b3-aa10-4760-ca77-ff681584827d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ln -s gdrive/'Team Drives'/'Data Mining Team'/ gdata"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "luXf_OC4xj-3",
        "colab_type": "code",
        "outputId": "4ad31203-610a-4e1e-ba76-7aeb1c3792bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/67/f7/1462c6d28ec27ef2812aa2e9376c7fc7b39a23f0e02297f71119d74375c5/contractions-0.0.18-py2.py3-none-any.whl\n",
            "Installing collected packages: contractions\n",
            "Successfully installed contractions-0.0.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_gqIeCczxrMV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from tf.keras.models import Sequential  # This does not work!\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L6B4Xnbrxllw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WdZuCaRCx-DJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Importing Libraries from Keras.\n"
      ]
    },
    {
      "metadata": {
        "id": "sV3EeIDyxyKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "loxaQYLfyFod",
        "colab_type": "code",
        "outputId": "82f46dc0-fe74-4a1b-db64-356dddd83243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Checking the version on Tensorflow\n",
        "tf.__version__\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "aMH6BXckyNPp",
        "colab_type": "code",
        "outputId": "da82ab37-a749-49d6-df25-f52a227b2338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Checking the version of Keras\n",
        "tf.keras.__version__\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4-tf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "lWI92Z8HyZcS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load Data\n"
      ]
    },
    {
      "metadata": {
        "id": "Pa9qrdmMyeu9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "connection = sqlite3.connect('gdata/yelpHotelData.db')\n",
        "x1 = connection.execute(\"select * FROM review\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O5MA6DYHyRSp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c28cd2d-0d91-4fad-9aa5-1ea9926923db"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(688329, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "T4eFQJ-AyoSS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "description = []\n",
        "Class = []\n",
        "\n",
        "data = x1.fetchmany(688329)\n",
        "\n",
        "for x in data:\n",
        "  description.append(x[3])\n",
        "  Class.append(x[8])\n",
        "trainData = {'Class' : Class, 'Description' : description}\n",
        "df_X = pd.DataFrame(trainData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sXRxY9WYyr0W",
        "colab_type": "code",
        "outputId": "a526959e-b586-451b-e68d-ba14387ea54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#Convert NR->N , YR->Y\n",
        "df_X.loc[df_X['Class'] == \"NR\", 'Class'] = \"N\"\n",
        "df_X.loc[df_X['Class'] == \"YR\", 'Class'] = \"Y\"\n",
        "df_X['Class'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "N    420785\n",
              "Y    267544\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "0wxZw1G_yvwx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "azw9ygo4zI5t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_X['Description'],df_X['Class'], test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WEeoIK6zzQqQ",
        "colab_type": "code",
        "outputId": "9f6ffe54-8768-4fe4-cbec-1c4da3af07c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Checking the shape of Train and Test Data\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(481830,) (206499,)\n",
            "(481830,) (206499,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KHoTHysvznFd",
        "colab_type": "code",
        "outputId": "2534e713-cf3a-410f-8463-147359fcc7bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Checking the length of train and test data\n",
        "print(\"Train-set size: \", len(X_train))\n",
        "print(\"Test-set size:  \", len(X_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train-set size:  481830\n",
            "Test-set size:   206499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8mk2YOpd0bnT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Combine into one data-set for some uses below.\n",
        "data_text = X_train + X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B9HMVqX805Vo",
        "colab_type": "code",
        "outputId": "65126ea1-86e3-4a79-8f05-e795bb06969d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#Printing an example to see how data looks like\n",
        "X_train[1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The only place inside the Loop that you can stay for $55/night. Also, the only place you can have a picnic dinner and get a little frisky on the 17th floor roof and then wake up in your room the next morning to an army of ants going in on your picnic leftovers.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "cyJZjUU-1GZT",
        "colab_type": "code",
        "outputId": "5b459497-c805-44d1-b335-ec87269e8e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_train[1]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'N'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "GxZAyxGu1Nkq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenizer\n",
        "A neural network cannot work directly on text-strings so we must convert it somehow. There are two steps in this conversion, the first step is called the \"tokenizer\" which converts words to integers and is done on the data-set before it is input to the neural network. The second step is an integrated part of the neural network itself and is called the \"embedding\"-layer, which is described further below.\n",
        "\n",
        "We may instruct the tokenizer to only use e.g. the 10000 most popular words from the data-set.\n"
      ]
    },
    {
      "metadata": {
        "id": "sLMKCouK1VcM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_words = 10000\n",
        "tokenizer = Tokenizer(num_words=num_words)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gQU_A1N01b96",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The tokenizer can then be \"fitted\" to the data-set. This scans through all the text and strips it from unwanted characters such as punctuation, and also converts it to lower-case characters. The tokenizer then builds a vocabulary of all unique words along with various data-structures for accessing the data.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "eYGSiSEb1ebL",
        "colab_type": "code",
        "outputId": "49df856b-c63e-4039-831a-c9f99a8f7d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Tokenization of train data\n",
        "%%time\n",
        "X_train_token = tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 5s, sys: 108 ms, total: 1min 5s\n",
            "Wall time: 1min 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wm7lg8euzMAL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pickle_out = open(\"train_token.pickle\",\"wb\")\n",
        "pickle.dump(X_train_token, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HlNIXf2a1z0D",
        "colab_type": "code",
        "outputId": "63118d20-02be-4ff6-c59f-9f61e0e05ad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Tokenization of test data\n",
        "%%time\n",
        "X_test_token = tokenizer.fit_on_texts(X_test)\n",
        "pickle_out_test = open(\"test_token.pickle\",\"wb\")\n",
        "pickle.dump(X_test_token, pickle_out_test)\n",
        "pickle_out_test.close()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 30.4 s, sys: 94.7 ms, total: 30.5 s\n",
            "Wall time: 30.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lrkQiKCt185i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#set num_words=None above, and then it will automatically be set to the vocabulary-size here.\n",
        "\n",
        "\n",
        "if num_words is None:\n",
        "    num_words = len(tokenizer.word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z5cR1ZEK2JhX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can then inspect the vocabulary that has been gathered by the tokenizer. This is ordered by the number of occurrences of the words in the data-set. These integer-numbers are called word indices or \"tokens\" because they uniquely identify each word in the vocabulary."
      ]
    },
    {
      "metadata": {
        "id": "h89DHq5K2GsI",
        "colab_type": "code",
        "outputId": "f1661be9-5245-4d57-fe48-d0dab7f40658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17034
        }
      },
      "cell_type": "code",
      "source": [
        "tokenizer.word_index\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'and': 2,\n",
              " 'a': 3,\n",
              " 'i': 4,\n",
              " 'to': 5,\n",
              " 'of': 6,\n",
              " 'was': 7,\n",
              " 'in': 8,\n",
              " 'is': 9,\n",
              " 'it': 10,\n",
              " 'for': 11,\n",
              " 'that': 12,\n",
              " 'but': 13,\n",
              " 'with': 14,\n",
              " 'you': 15,\n",
              " 'my': 16,\n",
              " 'on': 17,\n",
              " 'this': 18,\n",
              " 'they': 19,\n",
              " 'have': 20,\n",
              " 'we': 21,\n",
              " 'not': 22,\n",
              " 'at': 23,\n",
              " 'so': 24,\n",
              " 'had': 25,\n",
              " 'are': 26,\n",
              " 'were': 27,\n",
              " 'good': 28,\n",
              " 'place': 29,\n",
              " 'as': 30,\n",
              " 'be': 31,\n",
              " 'like': 32,\n",
              " 'here': 33,\n",
              " 'me': 34,\n",
              " 'there': 35,\n",
              " 'out': 36,\n",
              " 'all': 37,\n",
              " 'food': 38,\n",
              " 'if': 39,\n",
              " 'just': 40,\n",
              " 'one': 41,\n",
              " '\\xa0': 42,\n",
              " \"it's\": 43,\n",
              " 'or': 44,\n",
              " 'get': 45,\n",
              " 'up': 46,\n",
              " 'from': 47,\n",
              " 'great': 48,\n",
              " 'very': 49,\n",
              " 'some': 50,\n",
              " '\\xa0i': 51,\n",
              " 'really': 52,\n",
              " 'their': 53,\n",
              " 'when': 54,\n",
              " 'about': 55,\n",
              " '\\xa0the': 56,\n",
              " 'an': 57,\n",
              " 'time': 58,\n",
              " 'which': 59,\n",
              " 'can': 60,\n",
              " 'go': 61,\n",
              " 'our': 62,\n",
              " 'your': 63,\n",
              " 'more': 64,\n",
              " 'what': 65,\n",
              " 'would': 66,\n",
              " 'back': 67,\n",
              " 'also': 68,\n",
              " 'service': 69,\n",
              " 'by': 70,\n",
              " 'only': 71,\n",
              " 'too': 72,\n",
              " \"don't\": 73,\n",
              " 'no': 74,\n",
              " 'been': 75,\n",
              " 'nice': 76,\n",
              " 'little': 77,\n",
              " \"i'm\": 78,\n",
              " 'other': 79,\n",
              " 'because': 80,\n",
              " 'got': 81,\n",
              " 'well': 82,\n",
              " 'pretty': 83,\n",
              " 'do': 84,\n",
              " 'than': 85,\n",
              " 'even': 86,\n",
              " 'will': 87,\n",
              " 'has': 88,\n",
              " 'much': 89,\n",
              " 'them': 90,\n",
              " 'people': 91,\n",
              " 'us': 92,\n",
              " 'after': 93,\n",
              " \"i've\": 94,\n",
              " \"didn't\": 95,\n",
              " 'bar': 96,\n",
              " 'love': 97,\n",
              " 'think': 98,\n",
              " 'know': 99,\n",
              " 'he': 100,\n",
              " 'night': 101,\n",
              " 'best': 102,\n",
              " 'could': 103,\n",
              " 'way': 104,\n",
              " 'over': 105,\n",
              " 'did': 106,\n",
              " 'first': 107,\n",
              " 'restaurant': 108,\n",
              " 'came': 109,\n",
              " 'always': 110,\n",
              " 'who': 111,\n",
              " 'menu': 112,\n",
              " '2': 113,\n",
              " 'she': 114,\n",
              " 'off': 115,\n",
              " 'two': 116,\n",
              " 'make': 117,\n",
              " 'day': 118,\n",
              " 'better': 119,\n",
              " 'come': 120,\n",
              " 'right': 121,\n",
              " 'chicken': 122,\n",
              " 'how': 123,\n",
              " 'went': 124,\n",
              " 'ordered': 125,\n",
              " 'around': 126,\n",
              " 'try': 127,\n",
              " 'order': 128,\n",
              " 'then': 129,\n",
              " 'going': 130,\n",
              " 'see': 131,\n",
              " 'down': 132,\n",
              " 'room': 133,\n",
              " 'few': 134,\n",
              " '5': 135,\n",
              " 'made': 136,\n",
              " 'want': 137,\n",
              " 'bit': 138,\n",
              " 'though': 139,\n",
              " 'still': 140,\n",
              " 'friendly': 141,\n",
              " '3': 142,\n",
              " 'area': 143,\n",
              " 'definitely': 144,\n",
              " 'never': 145,\n",
              " 'while': 146,\n",
              " 'into': 147,\n",
              " 'before': 148,\n",
              " 'any': 149,\n",
              " 'am': 150,\n",
              " 'cheese': 151,\n",
              " 'say': 152,\n",
              " 'small': 153,\n",
              " 'since': 154,\n",
              " 'lot': 155,\n",
              " 'find': 156,\n",
              " 'sure': 157,\n",
              " 'staff': 158,\n",
              " 'new': 159,\n",
              " 'take': 160,\n",
              " 'most': 161,\n",
              " 'something': 162,\n",
              " 'again': 163,\n",
              " 'where': 164,\n",
              " 'delicious': 165,\n",
              " \"you're\": 166,\n",
              " 'now': 167,\n",
              " 'lunch': 168,\n",
              " 'next': 169,\n",
              " '\\xa0it': 170,\n",
              " 'sauce': 171,\n",
              " 'her': 172,\n",
              " \"wasn't\": 173,\n",
              " 'table': 174,\n",
              " 'many': 175,\n",
              " 'dinner': 176,\n",
              " 'eat': 177,\n",
              " 'big': 178,\n",
              " 'wait': 179,\n",
              " 'fresh': 180,\n",
              " 'thing': 181,\n",
              " 'bad': 182,\n",
              " 'experience': 183,\n",
              " 'salad': 184,\n",
              " 'being': 185,\n",
              " 'store': 186,\n",
              " 'ever': 187,\n",
              " '4': 188,\n",
              " \"can't\": 189,\n",
              " '1': 190,\n",
              " 'everything': 191,\n",
              " 'last': 192,\n",
              " 'pizza': 193,\n",
              " 'said': 194,\n",
              " 'location': 195,\n",
              " 'long': 196,\n",
              " 'side': 197,\n",
              " 'give': 198,\n",
              " 'drinks': 199,\n",
              " 'wine': 200,\n",
              " 'hot': 201,\n",
              " '\\xa0they': 202,\n",
              " 'enough': 203,\n",
              " 'things': 204,\n",
              " 'need': 205,\n",
              " 'every': 206,\n",
              " 'its': 207,\n",
              " 'another': 208,\n",
              " 'stars': 209,\n",
              " 'meal': 210,\n",
              " '\\xa0we': 211,\n",
              " 'free': 212,\n",
              " 'times': 213,\n",
              " \"that's\": 214,\n",
              " 'work': 215,\n",
              " 'looking': 216,\n",
              " 'actually': 217,\n",
              " 'feel': 218,\n",
              " 'beer': 219,\n",
              " 'price': 220,\n",
              " 'those': 221,\n",
              " \"i'd\": 222,\n",
              " 'minutes': 223,\n",
              " 'selection': 224,\n",
              " 'quite': 225,\n",
              " 'home': 226,\n",
              " 'probably': 227,\n",
              " 'hotel': 228,\n",
              " 'sweet': 229,\n",
              " 'amazing': 230,\n",
              " 'friend': 231,\n",
              " 'prices': 232,\n",
              " 'drink': 233,\n",
              " 'old': 234,\n",
              " 'his': 235,\n",
              " 'tasty': 236,\n",
              " 'took': 237,\n",
              " 'both': 238,\n",
              " 'parking': 239,\n",
              " 'worth': 240,\n",
              " '10': 241,\n",
              " 'happy': 242,\n",
              " 'friends': 243,\n",
              " 'these': 244,\n",
              " 'should': 245,\n",
              " 'kind': 246,\n",
              " 'check': 247,\n",
              " 'thought': 248,\n",
              " 'coffee': 249,\n",
              " 'fun': 250,\n",
              " 'huge': 251,\n",
              " 'awesome': 252,\n",
              " 'wanted': 253,\n",
              " 'super': 254,\n",
              " 'away': 255,\n",
              " 'places': 256,\n",
              " 'look': 257,\n",
              " 'favorite': 258,\n",
              " 'nothing': 259,\n",
              " 'different': 260,\n",
              " 'full': 261,\n",
              " 'ok': 262,\n",
              " 'same': 263,\n",
              " 'found': 264,\n",
              " 'cool': 265,\n",
              " 'meat': 266,\n",
              " 'tried': 267,\n",
              " 'large': 268,\n",
              " 'sandwich': 269,\n",
              " 'special': 270,\n",
              " 'why': 271,\n",
              " 'perfect': 272,\n",
              " 'decent': 273,\n",
              " 'bread': 274,\n",
              " 'taste': 275,\n",
              " 'top': 276,\n",
              " 'through': 277,\n",
              " 'cream': 278,\n",
              " 'fries': 279,\n",
              " 'burger': 280,\n",
              " 'once': 281,\n",
              " 'hour': 282,\n",
              " 'dish': 283,\n",
              " 'years': 284,\n",
              " 'line': 285,\n",
              " 'maybe': 286,\n",
              " 'fried': 287,\n",
              " 'spot': 288,\n",
              " \"i'll\": 289,\n",
              " 'open': 290,\n",
              " 'inside': 291,\n",
              " 'anything': 292,\n",
              " 'chocolate': 293,\n",
              " 'outside': 294,\n",
              " \"there's\": 295,\n",
              " 'breakfast': 296,\n",
              " 'street': 297,\n",
              " 'each': 298,\n",
              " 'getting': 299,\n",
              " 'clean': 300,\n",
              " 'used': 301,\n",
              " 'review': 302,\n",
              " 'visit': 303,\n",
              " 'soup': 304,\n",
              " 'rice': 305,\n",
              " 'sushi': 306,\n",
              " 'high': 307,\n",
              " 'star': 308,\n",
              " 'asked': 309,\n",
              " 'beef': 310,\n",
              " 'yelp': 311,\n",
              " 'half': 312,\n",
              " 'couple': 313,\n",
              " 'however': 314,\n",
              " 'walk': 315,\n",
              " 'quality': 316,\n",
              " 'stuff': 317,\n",
              " 'flavor': 318,\n",
              " 'end': 319,\n",
              " '\\xa0and': 320,\n",
              " 'excellent': 321,\n",
              " 'else': 322,\n",
              " 'least': 323,\n",
              " 'during': 324,\n",
              " 'oh': 325,\n",
              " 'having': 326,\n",
              " 'house': 327,\n",
              " 'without': 328,\n",
              " 'left': 329,\n",
              " 'told': 330,\n",
              " 'served': 331,\n",
              " 'front': 332,\n",
              " 'looked': 333,\n",
              " 'city': 334,\n",
              " 'usually': 335,\n",
              " 'ice': 336,\n",
              " 'course': 337,\n",
              " 'hard': 338,\n",
              " 'almost': 339,\n",
              " 'fish': 340,\n",
              " 'whole': 341,\n",
              " 'tables': 342,\n",
              " 'part': 343,\n",
              " 'put': 344,\n",
              " 'stop': 345,\n",
              " 'everyone': 346,\n",
              " 'items': 347,\n",
              " \"\\xa0it's\": 348,\n",
              " 'pork': 349,\n",
              " 'yes': 350,\n",
              " 'three': 351,\n",
              " 'may': 352,\n",
              " 'cheap': 353,\n",
              " 'overall': 354,\n",
              " 'recommend': 355,\n",
              " 'water': 356,\n",
              " 'dishes': 357,\n",
              " 'chicago': 358,\n",
              " 'decided': 359,\n",
              " 'dessert': 360,\n",
              " 'music': 361,\n",
              " \"isn't\": 362,\n",
              " '\\xa0but': 363,\n",
              " 'atmosphere': 364,\n",
              " 'especially': 365,\n",
              " 'such': 366,\n",
              " 'red': 367,\n",
              " 'spicy': 368,\n",
              " 'might': 369,\n",
              " 'less': 370,\n",
              " 'shop': 371,\n",
              " 'loved': 372,\n",
              " 'makes': 373,\n",
              " '6': 374,\n",
              " 'far': 375,\n",
              " '\\xa0my': 376,\n",
              " 'own': 377,\n",
              " 'park': 378,\n",
              " '\\xa0this': 379,\n",
              " 'dining': 380,\n",
              " 'done': 381,\n",
              " 'enjoy': 382,\n",
              " 'enjoyed': 383,\n",
              " 'use': 384,\n",
              " 'hours': 385,\n",
              " 'town': 386,\n",
              " 'liked': 387,\n",
              " 'eating': 388,\n",
              " 'must': 389,\n",
              " 'seemed': 390,\n",
              " 'door': 391,\n",
              " 'him': 392,\n",
              " \"doesn't\": 393,\n",
              " 'close': 394,\n",
              " 'server': 395,\n",
              " 'quick': 396,\n",
              " 'car': 397,\n",
              " 'show': 398,\n",
              " 'space': 399,\n",
              " 'lots': 400,\n",
              " 'party': 401,\n",
              " 'does': 402,\n",
              " 'week': 403,\n",
              " 'fan': 404,\n",
              " 'coming': 405,\n",
              " 'ask': 406,\n",
              " 'steak': 407,\n",
              " 'let': 408,\n",
              " 'able': 409,\n",
              " 'etc': 410,\n",
              " 'restaurants': 411,\n",
              " '20': 412,\n",
              " '30': 413,\n",
              " 'although': 414,\n",
              " 'someone': 415,\n",
              " 'tea': 416,\n",
              " 'pay': 417,\n",
              " 'trying': 418,\n",
              " 'either': 419,\n",
              " 'stay': 420,\n",
              " 'decor': 421,\n",
              " 'guy': 422,\n",
              " 'myself': 423,\n",
              " 'year': 424,\n",
              " 'felt': 425,\n",
              " 'sit': 426,\n",
              " 'group': 427,\n",
              " 'fact': 428,\n",
              " 'shrimp': 429,\n",
              " 'fast': 430,\n",
              " 'until': 431,\n",
              " \"couldn't\": 432,\n",
              " 'style': 433,\n",
              " 'name': 434,\n",
              " 'person': 435,\n",
              " 'business': 436,\n",
              " 'deal': 437,\n",
              " 'tell': 438,\n",
              " 'yet': 439,\n",
              " 'okay': 440,\n",
              " 'fine': 441,\n",
              " 'tasted': 442,\n",
              " 'gave': 443,\n",
              " 'plate': 444,\n",
              " 'guess': 445,\n",
              " 'live': 446,\n",
              " 'cake': 447,\n",
              " 'seems': 448,\n",
              " 'local': 449,\n",
              " 'days': 450,\n",
              " 'bring': 451,\n",
              " 'started': 452,\n",
              " 'buy': 453,\n",
              " 'plus': 454,\n",
              " 'white': 455,\n",
              " 'waiting': 456,\n",
              " 'walked': 457,\n",
              " 'call': 458,\n",
              " 'saw': 459,\n",
              " 'comes': 460,\n",
              " 'instead': 461,\n",
              " 'called': 462,\n",
              " 'finally': 463,\n",
              " 'real': 464,\n",
              " 'beautiful': 465,\n",
              " 'late': 466,\n",
              " 'needed': 467,\n",
              " '7': 468,\n",
              " 'options': 469,\n",
              " \"they're\": 470,\n",
              " 'busy': 471,\n",
              " '8': 472,\n",
              " 'fantastic': 473,\n",
              " 'keep': 474,\n",
              " 'reviews': 475,\n",
              " 'family': 476,\n",
              " 'easy': 477,\n",
              " 'later': 478,\n",
              " 'expensive': 479,\n",
              " 'cute': 480,\n",
              " 'extra': 481,\n",
              " '\\xa0if': 482,\n",
              " 'seating': 483,\n",
              " 'size': 484,\n",
              " 'point': 485,\n",
              " '15': 486,\n",
              " 'cold': 487,\n",
              " 'cooked': 488,\n",
              " 'green': 489,\n",
              " 'several': 490,\n",
              " 'list': 491,\n",
              " 'wonderful': 492,\n",
              " '50': 493,\n",
              " 'floor': 494,\n",
              " 'roll': 495,\n",
              " 'second': 496,\n",
              " 'remember': 497,\n",
              " 'helpful': 498,\n",
              " \"wouldn't\": 499,\n",
              " \"you'll\": 500,\n",
              " 'trip': 501,\n",
              " 'expect': 502,\n",
              " '\\xa0there': 503,\n",
              " 'waitress': 504,\n",
              " 'light': 505,\n",
              " 'warm': 506,\n",
              " 'help': 507,\n",
              " 'pick': 508,\n",
              " 'wrong': 509,\n",
              " 'glass': 510,\n",
              " 'early': 511,\n",
              " 'reason': 512,\n",
              " 'between': 513,\n",
              " '\\xa0you': 514,\n",
              " 'rooms': 515,\n",
              " 'care': 516,\n",
              " 'bacon': 517,\n",
              " 'money': 518,\n",
              " 'run': 519,\n",
              " 'crowd': 520,\n",
              " 'across': 521,\n",
              " 'weekend': 522,\n",
              " 'thai': 523,\n",
              " 'w': 524,\n",
              " 'job': 525,\n",
              " 'start': 526,\n",
              " \"won't\": 527,\n",
              " 'regular': 528,\n",
              " 'rolls': 529,\n",
              " 'brought': 530,\n",
              " 'mind': 531,\n",
              " 'plenty': 532,\n",
              " 'mean': 533,\n",
              " 'french': 534,\n",
              " 'crowded': 535,\n",
              " 'ended': 536,\n",
              " 'seem': 537,\n",
              " 'wish': 538,\n",
              " 'set': 539,\n",
              " 'looks': 540,\n",
              " 'gets': 541,\n",
              " 'rather': 542,\n",
              " 'totally': 543,\n",
              " 'ago': 544,\n",
              " 'owner': 545,\n",
              " 'chips': 546,\n",
              " 'saturday': 547,\n",
              " 'sandwiches': 548,\n",
              " 'yummy': 549,\n",
              " 'life': 550,\n",
              " '\\xa0so': 551,\n",
              " 'hit': 552,\n",
              " 'walking': 553,\n",
              " 'packed': 554,\n",
              " 'seen': 555,\n",
              " 'offer': 556,\n",
              " 'interesting': 557,\n",
              " 'drive': 558,\n",
              " 'view': 559,\n",
              " 'past': 560,\n",
              " 'morning': 561,\n",
              " 'counter': 562,\n",
              " 'making': 563,\n",
              " 'already': 564,\n",
              " 'choice': 565,\n",
              " 'sat': 566,\n",
              " 'along': 567,\n",
              " 'average': 568,\n",
              " 'near': 569,\n",
              " 'itself': 570,\n",
              " 'often': 571,\n",
              " 'kids': 572,\n",
              " 'evening': 573,\n",
              " 'cut': 574,\n",
              " 'main': 575,\n",
              " 'perfectly': 576,\n",
              " 'serve': 577,\n",
              " 'waiter': 578,\n",
              " 'flavors': 579,\n",
              " 'customer': 580,\n",
              " 'italian': 581,\n",
              " 'world': 582,\n",
              " 'absolutely': 583,\n",
              " 'four': 584,\n",
              " 'leave': 585,\n",
              " 'dog': 586,\n",
              " 'guys': 587,\n",
              " 'variety': 588,\n",
              " 'located': 589,\n",
              " 'event': 590,\n",
              " 'seated': 591,\n",
              " 'brunch': 592,\n",
              " 'ate': 593,\n",
              " 'today': 594,\n",
              " 'under': 595,\n",
              " 'neighborhood': 596,\n",
              " 'working': 597,\n",
              " 'chinese': 598,\n",
              " 'bbq': 599,\n",
              " 'hair': 600,\n",
              " 'type': 601,\n",
              " 'knew': 602,\n",
              " 'crab': 603,\n",
              " 'short': 604,\n",
              " 'sometimes': 605,\n",
              " 'grilled': 606,\n",
              " '\\xa0a': 607,\n",
              " 'head': 608,\n",
              " 'arrived': 609,\n",
              " 'sitting': 610,\n",
              " 'quickly': 611,\n",
              " 'black': 612,\n",
              " 'amount': 613,\n",
              " 'impressed': 614,\n",
              " 'disappointed': 615,\n",
              " 'la': 616,\n",
              " 'cafe': 617,\n",
              " 'patio': 618,\n",
              " 'downtown': 619,\n",
              " 'reasonable': 620,\n",
              " 'man': 621,\n",
              " 'kitchen': 622,\n",
              " 'seriously': 623,\n",
              " 'http': 624,\n",
              " 'dry': 625,\n",
              " 'garlic': 626,\n",
              " 'shopping': 627,\n",
              " 'egg': 628,\n",
              " 'doing': 629,\n",
              " 'believe': 630,\n",
              " 'available': 631,\n",
              " 'extremely': 632,\n",
              " 'mexican': 633,\n",
              " 'potato': 634,\n",
              " 'heard': 635,\n",
              " 'sunday': 636,\n",
              " 'game': 637,\n",
              " 'return': 638,\n",
              " 'entire': 639,\n",
              " 'watch': 640,\n",
              " 'comfortable': 641,\n",
              " 'given': 642,\n",
              " 'portions': 643,\n",
              " 'potatoes': 644,\n",
              " 'problem': 645,\n",
              " 'pasta': 646,\n",
              " 'club': 647,\n",
              " 'behind': 648,\n",
              " 'girl': 649,\n",
              " 'attentive': 650,\n",
              " '9': 651,\n",
              " 'stopped': 652,\n",
              " 'slow': 653,\n",
              " 'building': 654,\n",
              " 'soon': 655,\n",
              " 'bite': 656,\n",
              " 'tacos': 657,\n",
              " 'hand': 658,\n",
              " 'center': 659,\n",
              " 'butter': 660,\n",
              " 'burgers': 661,\n",
              " 'anyone': 662,\n",
              " 'bottle': 663,\n",
              " 'priced': 664,\n",
              " 'b': 665,\n",
              " 'pieces': 666,\n",
              " 'beers': 667,\n",
              " 'seafood': 668,\n",
              " 'rest': 669,\n",
              " 'appetizer': 670,\n",
              " 'friday': 671,\n",
              " 'surprised': 672,\n",
              " 'ones': 673,\n",
              " '12': 674,\n",
              " \"\\xa0i'm\": 675,\n",
              " 'sort': 676,\n",
              " 'eggs': 677,\n",
              " 'others': 678,\n",
              " 'idea': 679,\n",
              " 'ready': 680,\n",
              " 'dark': 681,\n",
              " '\\xa0not': 682,\n",
              " 'highly': 683,\n",
              " 'read': 684,\n",
              " 'beans': 685,\n",
              " \"haven't\": 686,\n",
              " 'five': 687,\n",
              " 'market': 688,\n",
              " 'pricey': 689,\n",
              " 'taking': 690,\n",
              " 'bathroom': 691,\n",
              " 'date': 692,\n",
              " 'kept': 693,\n",
              " 'crispy': 694,\n",
              " 'including': 695,\n",
              " 'anyway': 696,\n",
              " 'tasting': 697,\n",
              " 'yourself': 698,\n",
              " 'school': 699,\n",
              " \"weren't\": 700,\n",
              " 'tip': 701,\n",
              " 'middle': 702,\n",
              " 'bowl': 703,\n",
              " 'simple': 704,\n",
              " 'wall': 705,\n",
              " 'sign': 706,\n",
              " 'add': 707,\n",
              " \"aren't\": 708,\n",
              " 'husband': 709,\n",
              " 'portion': 710,\n",
              " 'card': 711,\n",
              " 'noodles': 712,\n",
              " 'filled': 713,\n",
              " 'together': 714,\n",
              " 'summer': 715,\n",
              " 'mall': 716,\n",
              " 'tiny': 717,\n",
              " 'feeling': 718,\n",
              " 'case': 719,\n",
              " 'recently': 720,\n",
              " 'san': 721,\n",
              " 'ambiance': 722,\n",
              " 'birthday': 723,\n",
              " 'tomato': 724,\n",
              " 'soft': 725,\n",
              " 'note': 726,\n",
              " 'completely': 727,\n",
              " 'standard': 728,\n",
              " 'solid': 729,\n",
              " 'pool': 730,\n",
              " 'bartender': 731,\n",
              " 'salmon': 732,\n",
              " 'salsa': 733,\n",
              " 'office': 734,\n",
              " 'bought': 735,\n",
              " 'glad': 736,\n",
              " 'ordering': 737,\n",
              " 'thanks': 738,\n",
              " 'loud': 739,\n",
              " 'spend': 740,\n",
              " 'miss': 741,\n",
              " 'yeah': 742,\n",
              " 'number': 743,\n",
              " 'unique': 744,\n",
              " 'change': 745,\n",
              " 'lovely': 746,\n",
              " 'prepared': 747,\n",
              " 'tuna': 748,\n",
              " 'exactly': 749,\n",
              " 'gone': 750,\n",
              " 'non': 751,\n",
              " 'sausage': 752,\n",
              " 'www': 753,\n",
              " 'afternoon': 754,\n",
              " 'crust': 755,\n",
              " 'choose': 756,\n",
              " 'please': 757,\n",
              " 'cup': 758,\n",
              " 'within': 759,\n",
              " 'com': 760,\n",
              " 'empty': 761,\n",
              " 'corner': 762,\n",
              " 'appetizers': 763,\n",
              " 'bill': 764,\n",
              " 'low': 765,\n",
              " 'blue': 766,\n",
              " 'cost': 767,\n",
              " 'art': 768,\n",
              " '25': 769,\n",
              " 'option': 770,\n",
              " 'yum': 771,\n",
              " 'crazy': 772,\n",
              " 'buffet': 773,\n",
              " 'expected': 774,\n",
              " 'phone': 775,\n",
              " 'stores': 776,\n",
              " 'tender': 777,\n",
              " 'stayed': 778,\n",
              " 'fruit': 779,\n",
              " 'hungry': 780,\n",
              " 'waited': 781,\n",
              " 'book': 782,\n",
              " 'wedding': 783,\n",
              " 'specials': 784,\n",
              " 'whatever': 785,\n",
              " 'outdoor': 786,\n",
              " 'beach': 787,\n",
              " 'slightly': 788,\n",
              " 'hear': 789,\n",
              " 'typical': 790,\n",
              " 'needs': 791,\n",
              " 'grab': 792,\n",
              " '\\xa0he': 793,\n",
              " 'onion': 794,\n",
              " 'lobster': 795,\n",
              " 'piece': 796,\n",
              " 'wow': 797,\n",
              " 'flavorful': 798,\n",
              " 'hate': 799,\n",
              " 'seat': 800,\n",
              " 'airport': 801,\n",
              " 'minute': 802,\n",
              " 'twice': 803,\n",
              " 'bed': 804,\n",
              " 'fairly': 805,\n",
              " 'ingredients': 806,\n",
              " 'entrees': 807,\n",
              " 'entree': 808,\n",
              " 'joint': 809,\n",
              " 'months': 810,\n",
              " 'folks': 811,\n",
              " 'plates': 812,\n",
              " 'cash': 813,\n",
              " 'thank': 814,\n",
              " 'weird': 815,\n",
              " 'damn': 816,\n",
              " 'based': 817,\n",
              " 'stand': 818,\n",
              " 'mix': 819,\n",
              " 'charge': 820,\n",
              " 'oil': 821,\n",
              " 'play': 822,\n",
              " 'offered': 823,\n",
              " 'watching': 824,\n",
              " 'c': 825,\n",
              " 'closed': 826,\n",
              " 'opened': 827,\n",
              " 'bland': 828,\n",
              " 'certainly': 829,\n",
              " 'onions': 830,\n",
              " 'goes': 831,\n",
              " 'lamb': 832,\n",
              " '\\xa0she': 833,\n",
              " 'pie': 834,\n",
              " 'mouth': 835,\n",
              " 'lady': 836,\n",
              " 'asian': 837,\n",
              " 'taco': 838,\n",
              " 'mixed': 839,\n",
              " 'section': 840,\n",
              " 'chain': 841,\n",
              " 'pleasant': 842,\n",
              " 'thin': 843,\n",
              " 'chef': 844,\n",
              " 'choices': 845,\n",
              " 'kinda': 846,\n",
              " 'customers': 847,\n",
              " 'per': 848,\n",
              " 'company': 849,\n",
              " 'recommended': 850,\n",
              " '\\xa0for': 851,\n",
              " 'upon': 852,\n",
              " 'tour': 853,\n",
              " 'paid': 854,\n",
              " 'seats': 855,\n",
              " 'deep': 856,\n",
              " 'class': 857,\n",
              " 'due': 858,\n",
              " 'above': 859,\n",
              " 'corn': 860,\n",
              " 'talk': 861,\n",
              " 'bars': 862,\n",
              " 'basically': 863,\n",
              " '\\xa0when': 864,\n",
              " 'modern': 865,\n",
              " 'lounge': 866,\n",
              " 'movie': 867,\n",
              " 'unless': 868,\n",
              " 'face': 869,\n",
              " 'giving': 870,\n",
              " 'eaten': 871,\n",
              " 'manager': 872,\n",
              " '11': 873,\n",
              " 'wife': 874,\n",
              " 'spent': 875,\n",
              " 'veggies': 876,\n",
              " 'baked': 877,\n",
              " 'level': 878,\n",
              " 'curry': 879,\n",
              " 'true': 880,\n",
              " 'total': 881,\n",
              " 'easily': 882,\n",
              " 'taken': 883,\n",
              " 'salads': 884,\n",
              " 'noticed': 885,\n",
              " 'station': 886,\n",
              " 'except': 887,\n",
              " 'running': 888,\n",
              " 'talking': 889,\n",
              " 'mom': 890,\n",
              " 'wings': 891,\n",
              " 'perhaps': 892,\n",
              " 'thinking': 893,\n",
              " 'hope': 894,\n",
              " 'bunch': 895,\n",
              " 'fancy': 896,\n",
              " 'share': 897,\n",
              " 'reservation': 898,\n",
              " 'worked': 899,\n",
              " 'boyfriend': 900,\n",
              " 'stuffed': 901,\n",
              " 'mostly': 902,\n",
              " 'turned': 903,\n",
              " 'added': 904,\n",
              " 'understand': 905,\n",
              " 'american': 906,\n",
              " \"\\xa0i've\": 907,\n",
              " 'strong': 908,\n",
              " '00': 909,\n",
              " 'truly': 910,\n",
              " 'duck': 911,\n",
              " 'heart': 912,\n",
              " 'south': 913,\n",
              " 'means': 914,\n",
              " 'desserts': 915,\n",
              " 'shoes': 916,\n",
              " 'bag': 917,\n",
              " 'weeks': 918,\n",
              " 'immediately': 919,\n",
              " 'dance': 920,\n",
              " 'girls': 921,\n",
              " 'desk': 922,\n",
              " 'box': 923,\n",
              " 'literally': 924,\n",
              " 'spinach': 925,\n",
              " 'credit': 926,\n",
              " 'dressing': 927,\n",
              " 'playing': 928,\n",
              " 'burrito': 929,\n",
              " 'authentic': 930,\n",
              " 'paying': 931,\n",
              " 'chance': 932,\n",
              " 'nights': 933,\n",
              " 'foods': 934,\n",
              " 'salty': 935,\n",
              " 'vegetarian': 936,\n",
              " 'greasy': 937,\n",
              " 'picked': 938,\n",
              " 'moved': 939,\n",
              " 'toast': 940,\n",
              " 'medium': 941,\n",
              " 'saying': 942,\n",
              " 'apparently': 943,\n",
              " 'sides': 944,\n",
              " 'longer': 945,\n",
              " 'mine': 946,\n",
              " 'mini': 947,\n",
              " 'ribs': 948,\n",
              " 'filling': 949,\n",
              " 'move': 950,\n",
              " 'anywhere': 951,\n",
              " 'products': 952,\n",
              " 'excited': 953,\n",
              " 'chairs': 954,\n",
              " 'wines': 955,\n",
              " \"you've\": 956,\n",
              " 'hands': 957,\n",
              " 'servers': 958,\n",
              " 's': 959,\n",
              " 'unfortunately': 960,\n",
              " 'takes': 961,\n",
              " 'baby': 962,\n",
              " 'walls': 963,\n",
              " 'window': 964,\n",
              " 'salt': 965,\n",
              " 'rich': 966,\n",
              " 'dogs': 967,\n",
              " 'says': 968,\n",
              " 'strip': 969,\n",
              " 'eye': 970,\n",
              " 'cozy': 971,\n",
              " 'toppings': 972,\n",
              " 'japanese': 973,\n",
              " 'tv': 974,\n",
              " 'alone': 975,\n",
              " 'drinking': 976,\n",
              " 'm': 977,\n",
              " 'touch': 978,\n",
              " 'creamy': 979,\n",
              " 'fair': 980,\n",
              " 'meals': 981,\n",
              " 'vibe': 982,\n",
              " 'prefer': 983,\n",
              " 'single': 984,\n",
              " '\\xa0in': 985,\n",
              " 'massage': 986,\n",
              " 'hell': 987,\n",
              " 'cocktails': 988,\n",
              " 'despite': 989,\n",
              " 'mac': 990,\n",
              " 'orange': 991,\n",
              " 'seeing': 992,\n",
              " 'hang': 993,\n",
              " 'lines': 994,\n",
              " 'st': 995,\n",
              " 'smaller': 996,\n",
              " 'orders': 997,\n",
              " 'simply': 998,\n",
              " 'overpriced': 999,\n",
              " '\\xa0no': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "VOzK2GoK2hsu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can then use the tokenizer to convert all texts in the training-set to lists of these tokens."
      ]
    },
    {
      "metadata": {
        "id": "Z4dSCl0F2YmJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "um_Tps-A2t2d",
        "colab_type": "code",
        "outputId": "c43054ec-c820-42b3-ff0f-7659f4ff5fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "X_train[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The only place inside the Loop that you can stay for $55/night. Also, the only place you can have a picnic dinner and get a little frisky on the 17th floor roof and then wake up in your room the next morning to an army of ants going in on your picnic leftovers.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "-GKziOCE2zwB",
        "colab_type": "code",
        "outputId": "c73d00d8-c7df-4ac1-8d52-a11aa7ee882d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "np.array(X_train_tokens[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   4,  532,   15, 6561,   33,  186,  530,  190,    7,    1,  110,\n",
              "         57,    4,   24, 1262,   29,   84,  190,    7,   73,  488,    2,\n",
              "        337, 3245,    5,  963,   36,   23,    1,  960,   25,    4,  235,\n",
              "          9,   62,   31,   72,    5,  318,   35,  524,  360,  218,  596,\n",
              "         40,   29,    9,  472, 4889, 2395, 3222,   10,  466,    2,  567,\n",
              "        603,  691,   43,    8,   11,  194, 4677,   19,   68,   20,  114,\n",
              "        202,  624,  165,  567,   60, 8087,    8, 3506, 3322,  110,   21,\n",
              "       1262,    1, 4649, 2841, 1286,   12, 3270, 6521, 1521, 4296, 1696,\n",
              "         21, 1262,    1, 1359,  551, 2451,   17,    1,  110,  390,   21,\n",
              "        889,   36,    1,  712,  751,   17,    1,  489,  390, 2799,    1,\n",
              "       1911,  387,  232,    4,  375,    3,  132,    6,    1,  680,   19,\n",
              "       4147,  412, 6561,  375,    1,  489,  390,   29,   84,  147,    9,\n",
              "        166,   40, 3832,   59,  309,  137,  745,    1,    5,   15,  513,\n",
              "          6,  205,    5,   86,   14,   36,    6,  376, 1070,   51,   21,\n",
              "        209,    5, 2407,   54,  284,   44,  113,    8,    1,  143,  379,\n",
              "        262, 1478,   13,   45,    3,   72,   79, 1134,   14,    3,   42,\n",
              "        471])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "3rToCDDw3mUZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "DhgXmCf73A4k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We also need to convert the texts in the test-set to tokens."
      ]
    },
    {
      "metadata": {
        "id": "Vh1cpnNf290L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HbUNpQnC3Nvl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Padding and Truncating Data¶\n",
        "The Recurrent Neural Network can take sequences of arbitrary length as input, but in order to use a whole batch of data, the sequences need to have the same length. There are two ways of achieving this: (A) Either we ensure that all sequences in the entire data-set have the same length, or (B) we write a custom data-generator that ensures the sequences have the same length within each batch.\n",
        "\n",
        "Solution (A) is simpler but if we use the length of the longest sequence in the data-set, then we are wasting a lot of memory. This is particularly important for larger data-sets.\n",
        "\n",
        "So in order to make a compromise, we will use a sequence-length that covers most sequences in the data-set, and we will then truncate longer sequences and pad shorter sequences.\n",
        "\n",
        "First we count the number of tokens in all the sequences in the data-set."
      ]
    },
    {
      "metadata": {
        "id": "VnonWXPc3VCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_tokens = [len(tokens) for tokens in X_train_tokens + X_test_tokens]\n",
        "num_tokens = np.array(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kE0eW9yh3nqT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The average number of tokens in a sequence is:"
      ]
    },
    {
      "metadata": {
        "id": "l_CvxbHQ33ZT",
        "colab_type": "code",
        "outputId": "a824edf0-6a01-4829-86c6-d4975d717f7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.mean(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140.80798"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "rPRWwYok39Z-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The maximum number of tokens in a sequence is:"
      ]
    },
    {
      "metadata": {
        "id": "Mw1EM8DA3_-H",
        "colab_type": "code",
        "outputId": "9f861862-fdb3-4bc2-c997-d9e807bbab4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.max(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "989"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "-Fdl5ced4JZ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The max number of tokens we will allow is set to the average plus 2 standard deviations."
      ]
    },
    {
      "metadata": {
        "id": "hww_AqTx4MEh",
        "colab_type": "code",
        "outputId": "df00d116-1393-42e0-c19b-7c845e7e5c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
        "max_tokens = int(max_tokens)\n",
        "max_tokens"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "369"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "5ta5aQ8f4Vc-",
        "colab_type": "code",
        "outputId": "54a06a59-8b28-46e9-e41b-496038da5e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.sum(num_tokens < max_tokens) / len(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.95387"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "-gpSwjbO4biG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When padding or truncating the sequences that have a different length, we need to determine if we want to do this padding or truncating 'pre' or 'post'. If a sequence is truncated, it means that a part of the sequence is simply thrown away. If a sequence is padded, it means that zeros are added to the sequence.\n",
        "\n",
        "So the choice of 'pre' or 'post' can be important because it determines whether we throw away the first or last part of a sequence when truncating, and it determines whether we add zeros to the beginning or end of the sequence when padding. This may confuse the Recurrent Neural Network."
      ]
    },
    {
      "metadata": {
        "id": "f6Hsbc8W4hxw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pad = 'pre'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OCJdSfKF4kHQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_tokens,\n",
        "                            padding=pad, truncating=pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ky_gNfeH5tus",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_tokens,\n",
        "                           padding=pad, truncating=pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7woOO57951Kk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have now transformed the training-set into one big matrix of integers (tokens) with this shape:"
      ]
    },
    {
      "metadata": {
        "id": "Nnxp4Gvd56L9",
        "colab_type": "code",
        "outputId": "883769ee-87f2-41cb-fc42-300148358026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "X_train_pad.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 369)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "t73XrNAg6B29",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The matrix for the test-set has the same shape:"
      ]
    },
    {
      "metadata": {
        "id": "QVS6Q1HW6DCv",
        "colab_type": "code",
        "outputId": "ba56b798-7f51-40f6-85ab-ca09f020522a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_test_pad.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 369)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "ff2kzZjx6L1Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Change of sequence of tokens into padded sequence.Note that when this is input to the Recurrent Neural Network, then it first inputs a lot of zeros. If we had padded 'post' then it would input the integer-tokens first and then a lot of zeros. This may confuse the Recurrent Neural Network.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1TuD19Tx6XM7",
        "colab_type": "code",
        "outputId": "fe7e5415-d994-4ce4-d397-51e5b0d90399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "np.array(X_train_tokens[1])\n",
        "X_train_pad[1]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    4,  532,   15, 6561,   33,  186,\n",
              "        530,  190,    7,    1,  110,   57,    4,   24, 1262,   29,   84,\n",
              "        190,    7,   73,  488,    2,  337, 3245,    5,  963,   36,   23,\n",
              "          1,  960,   25,    4,  235,    9,   62,   31,   72,    5,  318,\n",
              "         35,  524,  360,  218,  596,   40,   29,    9,  472, 4889, 2395,\n",
              "       3222,   10,  466,    2,  567,  603,  691,   43,    8,   11,  194,\n",
              "       4677,   19,   68,   20,  114,  202,  624,  165,  567,   60, 8087,\n",
              "          8, 3506, 3322,  110,   21, 1262,    1, 4649, 2841, 1286,   12,\n",
              "       3270, 6521, 1521, 4296, 1696,   21, 1262,    1, 1359,  551, 2451,\n",
              "         17,    1,  110,  390,   21,  889,   36,    1,  712,  751,   17,\n",
              "          1,  489,  390, 2799,    1, 1911,  387,  232,    4,  375,    3,\n",
              "        132,    6,    1,  680,   19, 4147,  412, 6561,  375,    1,  489,\n",
              "        390,   29,   84,  147,    9,  166,   40, 3832,   59,  309,  137,\n",
              "        745,    1,    5,   15,  513,    6,  205,    5,   86,   14,   36,\n",
              "          6,  376, 1070,   51,   21,  209,    5, 2407,   54,  284,   44,\n",
              "        113,    8,    1,  143,  379,  262, 1478,   13,   45,    3,   72,\n",
              "         79, 1134,   14,    3,   42,  471], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "cjoL0cMU6hzx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Tokenizer Inverse Map**\n",
        "\n",
        "For some strange reason, the Keras implementation of a tokenizer does not seem to have the inverse mapping from integer-tokens back to words, which is needed to reconstruct text-strings from lists of tokens. So we make that mapping here."
      ]
    },
    {
      "metadata": {
        "id": "pE2-gWMz6nap",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx = tokenizer.word_index\n",
        "inverse_map = dict(zip(idx.values(), idx.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DTEF0gl17EID",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Helper-function for converting a list of tokens back to a string of words."
      ]
    },
    {
      "metadata": {
        "id": "249upoac7G93",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokens_to_string(tokens):\n",
        "    # Map from tokens back to words.\n",
        "    words = [inverse_map[token] for token in tokens if token != 0]\n",
        "    \n",
        "    # Concatenate all words.\n",
        "    text = \" \".join(words)\n",
        "\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KpGZa1Bo7JMT",
        "colab_type": "code",
        "outputId": "721d8bb7-ec94-4271-bed9-200e81e47cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#For example, this is the original text from the data-set:\n",
        "\n",
        "X_train[1]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The only place inside the Loop that you can stay for $55/night. Also, the only place you can have a picnic dinner and get a little frisky on the 17th floor roof and then wake up in your room the next morning to an army of ants going in on your picnic leftovers.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "CX83b1hj7UM8",
        "colab_type": "code",
        "outputId": "8afd3b99-759a-448e-dd97-ec294e11e748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "tokens_to_string(X_train_tokens[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"i brought my niece here last saturday \\xa0it was the first time i had visited as well \\xa0it was too cold and almost rainy to hang out at the beach so i thought it would be nice to walk there along park \\xa0we arrived just as it started raining adult admission is 7 and kids under 12 get in for free \\xa0apparently they also have day every sunday where kids can participate in artist lead first we visited the children's gallery downstairs that featured pin hole photography \\xa0then we visited the california seen exhibit on the first floor we checked out the modern art on the second floor \\xa0although the collection isn't huge i enjoyed a few of the pieces they displayed \\xa0my niece enjoyed the second floor as well since it wasn't just paintings \\xa0 i'll definitely add the to my list of things to do with out of town guests when we need to kill an hour or two in the area \\xa0it's nothing spectacular but it's a nice little museum with a great view\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "Q1lwXbDO7nTq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create the Recurrent Neural Network**\n"
      ]
    },
    {
      "metadata": {
        "id": "aUlcYzSR7war",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jOUcjmQA70D0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zEiHGsop7243",
        "colab_type": "code",
        "outputId": "e3bf13e1-5e9c-4078-96b4-e3925c58c4af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "model.add(Embedding(input_dim=num_words,\n",
        "                    output_dim=embedding_size,\n",
        "                    input_length=max_tokens,\n",
        "                    name='layer_embedding'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RSxS0bQ4762I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Adding the gated GRU\n",
        "model.add(GRU(units=16, return_sequences=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3HEo-f3j8DP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Adding the second GRU with 8 output units\n",
        "model.add(GRU(units=8, return_sequences=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BuYNAtaR8Lel",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This code adds the third and final GRU with 4 output units. This will be followed by a dense-layer, so it should only give the final output of the GRU and not a whole sequence of outputs.\n",
        "\n",
        "model.add(GRU(units=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "43DIqzSy8YrQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "dd a fully-connected / dense layer which computes a value between 0.0 and 1.0 that will be used as the classification output."
      ]
    },
    {
      "metadata": {
        "id": "Iuy0Ns1Z8elX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5tMNpwiZ8jQ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Adam optimizer with the given learning-rate.\n",
        "optimizer = Adam(lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xd22QhtM8pir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Compile the Keras model so it is ready for training.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UKp48z8I8t-O",
        "colab_type": "code",
        "outputId": "aae1110c-e43f-4337-ae72-1eaae9ccc002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "layer_embedding (Embedding)  (None, 369, 8)            80000     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 369, 16)           1200      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 369, 8)            600       \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 4)                 156       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 81,961\n",
            "Trainable params: 81,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aPleqvXQ8zJT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Train the Recurrent Neural Network**\n",
        "\n",
        "We can now train the model. Note that we are using the data-set with the padded sequences. We use 5% of the training-set as a small validation-set, so we have a rough idea whether the model is generalizing well or if it is perhaps over-fitting to the training-set."
      ]
    },
    {
      "metadata": {
        "id": "kjcKGk7lZ-tZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#print(y_train.loc[y_train['Class'] == \"N\"])\n",
        "def mapToBinary(x):\n",
        "  if x == 'Y':\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "  \n",
        "y_train_bin = list(map(mapToBinary, y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iEzDIMOP5Bxk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_bin = list(map(mapToBinary, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KvcbfmwK87I_",
        "colab_type": "code",
        "outputId": "5243ff73-ab2b-4646-9c51-6e14ce95778e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model.fit(X_train_pad, y_train_bin,\n",
        "          validation_split=0.05, epochs=1, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 66500 samples, validate on 3500 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "66500/66500 [==============================] - 1552s 23ms/sample - loss: 0.6627 - acc: 0.6112 - val_loss: 0.6273 - val_acc: 0.6409\n",
            "CPU times: user 36min 1s, sys: 2min 7s, total: 38min 9s\n",
            "Wall time: 25min 56s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f30714254a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "O46QrFzJN6sx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('gdata/my_model.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N1QAHnkh5DqT",
        "colab_type": "code",
        "outputId": "2debe469-453b-4857-a7c5-35a860684877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "X_test_pad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    4,  102,   22],\n",
              "       [   0,    0,    0, ...,   17,    1,  696],\n",
              "       [   0,    0,    0, ...,  473,   32, 1174],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,   57,   35,   73],\n",
              "       [   0,    0,    0, ...,  475,  151, 2051],\n",
              "       [   0,    0,    0, ...,    6,  220,  467]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "xYLE7XGWN5CK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1JqTZnJ_34XV",
        "colab_type": "code",
        "outputId": "c7871928-2f89-4077-c9cf-dba46e4161fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Performance on Test-Set\n",
        "# Now that the model has been trained we can calculate its classification accuracy on the test-set.\n",
        "\n",
        "%%time\n",
        "result = model.evaluate(X_test_pad, y_test_bin)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000/30000 [==============================] - 553s 18ms/sample - loss: 0.6369 - acc: 0.6298\n",
            "CPU times: user 14min 25s, sys: 1min 15s, total: 15min 40s\n",
            "Wall time: 9min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YiGfmD2z6dvj",
        "colab_type": "code",
        "outputId": "9bac7a81-8a35-4d2f-a61e-0463dfcbdbf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: {0:.2%}\".format(result[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 62.98%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2cUYR-bmdkS7",
        "colab_type": "code",
        "outputId": "87de9329-3e89-4985-d455-8cb9833b6c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test_pad)\n",
        "predictions_bin = list(map(lambda x: 1 if x>=0.5 else 0, predictions))\n",
        "predictions_bin\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "print(metrics.classification_report(y_test_bin, predictions_bin))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.90      0.75     18123\n",
            "           1       0.58      0.22      0.32     11877\n",
            "\n",
            "   micro avg       0.63      0.63      0.63     30000\n",
            "   macro avg       0.61      0.56      0.53     30000\n",
            "weighted avg       0.62      0.63      0.58     30000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pML5erMwRN6x",
        "colab_type": "code",
        "outputId": "7bda4af1-60b7-4515-ea09-1a005d84ec72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# #In order to show an example of mis-classified text, we first calculate the predicted sentiment for the first 1000 texts in the test-set.\n",
        "# %%time\n",
        "# y_pred = model.predict(x=X_test_pad[0:1000])\n",
        "# y_pred = y_pred.T[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 30.2 s, sys: 2.85 s, total: 33.1 s\n",
            "Wall time: 19.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fzVw7AkDcvdi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #These predicted numbers fall between 0.0 and 1.0. We use a cutoff / threshold and say that all values above 0.5 are taken to be 1.0 \n",
        "# #and all values below 0.5 are taken to be 0.0. This gives us a predicted \"class\" of either 0.0 or 1.0.\n",
        "# cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nUBS2JTGRdx6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #he true \"class\" for the first 1000 texts in the test-set are needed for comparison.\n",
        "\n",
        "# cls_true = np.array(y_test[0:1000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xx4Xd0gJc79E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #We can then get indices for all the texts that were incorrectly classified by comparing all the \"classes\" of these two arrays\n",
        "# incorrect = np.where(cls_pred != cls_true)\n",
        "# incorrect = incorrect[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vOnVcCuHdEi-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Of the 1000 texts used, how many were mis-classified?\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2d74LLuKcbTC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# y_test_bin = list(map(mapToBinary, y_test))\n",
        "\n",
        "# predictions = model.predict(X_test_pad)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bqiwr4Nteumo",
        "colab_type": "code",
        "outputId": "cd06d194-016a-4ba9-eec9-b90dc719d142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "cell_type": "code",
      "source": [
        "# predictions_bin = list(map(lambda x: 1 if x>=0.5 else 0, predictions))\n",
        "# predictions_bin\n",
        "\n",
        "# from sklearn import metrics\n",
        "\n",
        "# print(metrics.classification_report(y_test_bin, predictions_bin))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.92      0.84      2297\n",
            "           1       0.38      0.17      0.23       703\n",
            "\n",
            "   micro avg       0.74      0.74      0.74      3000\n",
            "   macro avg       0.58      0.54      0.54      3000\n",
            "weighted avg       0.69      0.74      0.70      3000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BlnXL3ufez9s",
        "colab_type": "code",
        "outputId": "def6c182-4b52-44e4-f955-f1c5ddf73ab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}